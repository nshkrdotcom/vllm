# Generated by SnakeBridge v0.16.0 - DO NOT EDIT MANUALLY
# Regenerate with: mix compile
# Library: vllm 0.14.0
# Python module: vllm.config
# Python class: VllmConfig

defmodule Vllm.Config.VllmConfig do
  @moduledoc """
  Dataclass which contains all vllm-related configuration. This

  simplifies passing around the distinct configurations in the codebase.
  """
  def __snakebridge_python_name__, do: "vllm.config"
  def __snakebridge_python_class__, do: "VllmConfig"
  def __snakebridge_library__, do: "vllm"
  @opaque t :: SnakeBridge.Ref.t()

  @doc """
  Constructs `VllmConfig`.

  ## Parameters

  - `dataclass_self__` (term())
  - `args` (term())
  - `kwargs` (term())
  """
  @spec new(term(), term(), term(), keyword()) ::
          {:ok, SnakeBridge.Ref.t()} | {:error, Snakepit.Error.t()}
  def new(dataclass_self__, args, kwargs, opts \\ []) do
    SnakeBridge.Runtime.call_class(__MODULE__, :__init__, [dataclass_self__, args, kwargs], opts)
  end

  @doc """
  Apply optimization level defaults using self as root.

  Recursively applies values from defaults into nested config objects.
  Only fields present in defaults are overwritten.

  If the user configuration does not specify a value for a default field
  and if the default field is still None after all user selections are
  applied, then default values will be applied to the field. User speciied
  fields will not be overridden by the default.

  ## Parameters

  - `defaults` - Dictionary of default values to apply.

  ## Returns

  - `nil`
  """
  @spec _apply_optimization_level_defaults(
          SnakeBridge.Ref.t(),
          %{optional(String.t()) => term()},
          keyword()
        ) :: {:ok, nil} | {:error, Snakepit.Error.t()}
  def _apply_optimization_level_defaults(ref, defaults, opts \\ []) do
    SnakeBridge.Runtime.call_method(ref, :_apply_optimization_level_defaults, [defaults], opts)
  end

  @doc """
  Get the quantization config.

  ## Parameters

  - `model_config` (term())
  - `load_config` (term())

  ## Returns

  - `term()`
  """
  @spec _get_quantization_config(SnakeBridge.Ref.t(), term(), term(), keyword()) ::
          {:ok, term()} | {:error, Snakepit.Error.t()}
  def _get_quantization_config(ref, model_config, load_config, opts \\ []) do
    SnakeBridge.Runtime.call_method(
      ref,
      :_get_quantization_config,
      [model_config, load_config],
      opts
    )
  end

  @doc """
  Update KVTransferConfig based on top-level configs in VllmConfig.

  Right now, this function reads the offloading settings from
  CacheConfig and configures the KVTransferConfig accordingly.

  ## Returns

  - `nil`
  """
  @spec _post_init_kv_transfer_config(SnakeBridge.Ref.t(), keyword()) ::
          {:ok, nil} | {:error, Snakepit.Error.t()}
  def _post_init_kv_transfer_config(ref, opts \\ []) do
    SnakeBridge.Runtime.call_method(ref, :_post_init_kv_transfer_config, [], opts)
  end

  @doc """
  Set the compile ranges for the compilation config.

  ## Returns

  - `term()`
  """
  @spec _set_compile_ranges(SnakeBridge.Ref.t(), keyword()) ::
          {:ok, term()} | {:error, Snakepit.Error.t()}
  def _set_compile_ranges(ref, opts \\ []) do
    SnakeBridge.Runtime.call_method(ref, :_set_compile_ranges, [], opts)
  end

  @doc """
  Set config attribute to default if not already set by user.



  ## Parameters

  - `config_obj` - Configuration object to update.
  - `key` - Attribute name.
  - `value` - Default value (static or callable).

  ## Returns

  - `nil`
  """
  @spec _set_config_default(SnakeBridge.Ref.t(), term(), String.t(), term(), keyword()) ::
          {:ok, nil} | {:error, Snakepit.Error.t()}
  def _set_config_default(ref, config_obj, key, value, opts \\ []) do
    SnakeBridge.Runtime.call_method(ref, :_set_config_default, [config_obj, key, value], opts)
  end

  @doc """
  vLLM defines the default candidate list of batch sizes for CUDA graph

  capture as:

  ```python
  max_graph_size = min(max_num_seqs * 2, 512)
  # 1, 2, 4, then multiples of 8 up to 256 and then multiples of 16
  # up to max_graph_size
  cudagraph_capture_sizes = [1, 2, 4] + list(range(8, 256, 8)) + list(
      range(256, max_graph_size + 1, 16))
  ```

  In the end, `vllm_config.compilation_config.cudagraph_capture_sizes`
  will be the final sizes to capture cudagraph (in ascending order).

  These sizes are used to capture and reuse CUDA graphs for
  performance-critical paths (e.g., decoding). Capturing enables
  significantly faster kernel dispatch by avoiding Python overhead. The
  list is then filtered based on `max_num_batched_tokens` (e.g., 8192 on
  most GPUs), which controls the total allowed number of tokens in a
  batch. Since each sequence may have a variable number of tokens, the
  maximum usable batch size will depend on actual sequence lengths.

  ## Examples

      With `max_num_batched_tokens = 8192`, and typical sequences
      averaging ~32 tokens, most practical batch sizes fall below 256.
      However, the system will still allow capture sizes up to 512 if
      shape and memory permit.

  ## Notes

  If users explicitly specify cudagraph capture sizes in the
      compilation config, those will override this default logic.
      At runtime:

      - If batch size <= one of the `cudagraph_capture_sizes`, the closest
      padded CUDA graph will be used.
      - If batch size > largest `cudagraph_capture_sizes`, cudagraph will
      not be used.

  ## Returns

  - `term()`
  """
  @spec _set_cudagraph_sizes(SnakeBridge.Ref.t(), keyword()) ::
          {:ok, term()} | {:error, Snakepit.Error.t()}
  def _set_cudagraph_sizes(ref, opts \\ []) do
    SnakeBridge.Runtime.call_method(ref, :_set_cudagraph_sizes, [], opts)
  end

  @doc """
  Returns a rank-aware path for dumping

  torch.compile debug information.

  ## Returns

  - `term()`
  """
  @spec compile_debug_dump_path(SnakeBridge.Ref.t(), keyword()) ::
          {:ok, term()} | {:error, Snakepit.Error.t()}
  def compile_debug_dump_path(ref, opts \\ []) do
    SnakeBridge.Runtime.call_method(ref, :compile_debug_dump_path, [], opts)
  end

  @doc """
  WARNING: Whenever a new field is added to this config,

  ensure that it is included in the factors list if
  it affects the computation graph.

  Provide a hash that uniquely identifies all the configs
  that affect the structure of the computation
  graph from input ids/embeddings to the final hidden states,
  excluding anything before input ids/embeddings and after
  the final hidden states.

  ## Returns

  - `String.t()`
  """
  @spec compute_hash(SnakeBridge.Ref.t(), keyword()) ::
          {:ok, String.t()} | {:error, Snakepit.Error.t()}
  def compute_hash(ref, opts \\ []) do
    SnakeBridge.Runtime.call_method(ref, :compute_hash, [], opts)
  end

  @doc """
  Set up function tracing for the current thread,

  if enabled via the `VLLM_TRACE_FUNCTION` environment variable.

  ## Returns

  - `nil`
  """
  @spec enable_trace_function_call_for_thread(SnakeBridge.Ref.t(), keyword()) ::
          {:ok, nil} | {:error, Snakepit.Error.t()}
  def enable_trace_function_call_for_thread(ref, opts \\ []) do
    SnakeBridge.Runtime.call_method(ref, :enable_trace_function_call_for_thread, [], opts)
  end

  @doc """
  Python method `VllmConfig.get_quantization_config`.

  ## Parameters

  - `model_config` (term())
  - `load_config` (term())

  ## Returns

  - `term()`
  """
  @spec get_quantization_config(SnakeBridge.Ref.t(), term(), term(), keyword()) ::
          {:ok, term()} | {:error, Snakepit.Error.t()}
  def get_quantization_config(ref, model_config, load_config, opts \\ []) do
    SnakeBridge.Runtime.call_method(
      ref,
      :get_quantization_config,
      [model_config, load_config],
      opts
    )
  end

  @doc """
  Python method `VllmConfig.pad_for_cudagraph`.

  ## Parameters

  - `batch_size` (integer())

  ## Returns

  - `integer()`
  """
  @spec pad_for_cudagraph(SnakeBridge.Ref.t(), integer(), keyword()) ::
          {:ok, integer()} | {:error, Snakepit.Error.t()}
  def pad_for_cudagraph(ref, batch_size, opts \\ []) do
    SnakeBridge.Runtime.call_method(ref, :pad_for_cudagraph, [batch_size], opts)
  end

  @doc """
  Python method `VllmConfig.try_verify_and_update_config`.

  ## Returns

  - `term()`
  """
  @spec try_verify_and_update_config(SnakeBridge.Ref.t(), keyword()) ::
          {:ok, term()} | {:error, Snakepit.Error.t()}
  def try_verify_and_update_config(ref, opts \\ []) do
    SnakeBridge.Runtime.call_method(ref, :try_verify_and_update_config, [], opts)
  end

  @doc """
  Python method `VllmConfig.update_sizes_for_sequence_parallelism`.

  ## Parameters

  - `possible_sizes` (list(term()))

  ## Returns

  - `list(term())`
  """
  @spec update_sizes_for_sequence_parallelism(SnakeBridge.Ref.t(), list(term()), keyword()) ::
          {:ok, list(term())} | {:error, Snakepit.Error.t()}
  def update_sizes_for_sequence_parallelism(ref, possible_sizes, opts \\ []) do
    SnakeBridge.Runtime.call_method(
      ref,
      :update_sizes_for_sequence_parallelism,
      [possible_sizes],
      opts
    )
  end

  @doc """
  Python method `VllmConfig.validate_mamba_block_size`.

  ## Returns

  - `term()`
  """
  @spec validate_mamba_block_size(SnakeBridge.Ref.t(), keyword()) ::
          {:ok, term()} | {:error, Snakepit.Error.t()}
  def validate_mamba_block_size(ref, opts \\ []) do
    SnakeBridge.Runtime.call_method(ref, :validate_mamba_block_size, [], opts)
  end

  @doc """
  Python method `VllmConfig.with_hf_config`.

  ## Parameters

  - `hf_config` (term())
  - `architectures` (term() default: None)

  ## Returns

  - `term()`
  """
  @spec with_hf_config(SnakeBridge.Ref.t(), term(), list(term()), keyword()) ::
          {:ok, term()} | {:error, Snakepit.Error.t()}
  def with_hf_config(ref, hf_config, args, opts \\ []) do
    {args, opts} = SnakeBridge.Runtime.normalize_args_opts(args, opts)
    SnakeBridge.Runtime.call_method(ref, :with_hf_config, [hf_config] ++ List.wrap(args), opts)
  end

  @spec additional_config(SnakeBridge.Ref.t()) :: {:ok, term()} | {:error, Snakepit.Error.t()}
  def additional_config(ref) do
    SnakeBridge.Runtime.get_attr(ref, :additional_config)
  end

  @spec attention_config(SnakeBridge.Ref.t()) :: {:ok, term()} | {:error, Snakepit.Error.t()}
  def attention_config(ref) do
    SnakeBridge.Runtime.get_attr(ref, :attention_config)
  end

  @spec cache_config(SnakeBridge.Ref.t()) :: {:ok, term()} | {:error, Snakepit.Error.t()}
  def cache_config(ref) do
    SnakeBridge.Runtime.get_attr(ref, :cache_config)
  end

  @spec compilation_config(SnakeBridge.Ref.t()) :: {:ok, term()} | {:error, Snakepit.Error.t()}
  def compilation_config(ref) do
    SnakeBridge.Runtime.get_attr(ref, :compilation_config)
  end

  @spec device_config(SnakeBridge.Ref.t()) :: {:ok, term()} | {:error, Snakepit.Error.t()}
  def device_config(ref) do
    SnakeBridge.Runtime.get_attr(ref, :device_config)
  end

  @spec ec_transfer_config(SnakeBridge.Ref.t()) :: {:ok, term()} | {:error, Snakepit.Error.t()}
  def ec_transfer_config(ref) do
    SnakeBridge.Runtime.get_attr(ref, :ec_transfer_config)
  end

  @spec instance_id(SnakeBridge.Ref.t()) :: {:ok, term()} | {:error, Snakepit.Error.t()}
  def instance_id(ref) do
    SnakeBridge.Runtime.get_attr(ref, :instance_id)
  end

  @spec kv_events_config(SnakeBridge.Ref.t()) :: {:ok, term()} | {:error, Snakepit.Error.t()}
  def kv_events_config(ref) do
    SnakeBridge.Runtime.get_attr(ref, :kv_events_config)
  end

  @spec kv_transfer_config(SnakeBridge.Ref.t()) :: {:ok, term()} | {:error, Snakepit.Error.t()}
  def kv_transfer_config(ref) do
    SnakeBridge.Runtime.get_attr(ref, :kv_transfer_config)
  end

  @spec load_config(SnakeBridge.Ref.t()) :: {:ok, term()} | {:error, Snakepit.Error.t()}
  def load_config(ref) do
    SnakeBridge.Runtime.get_attr(ref, :load_config)
  end

  @spec lora_config(SnakeBridge.Ref.t()) :: {:ok, term()} | {:error, Snakepit.Error.t()}
  def lora_config(ref) do
    SnakeBridge.Runtime.get_attr(ref, :lora_config)
  end

  @spec model_config(SnakeBridge.Ref.t()) :: {:ok, term()} | {:error, Snakepit.Error.t()}
  def model_config(ref) do
    SnakeBridge.Runtime.get_attr(ref, :model_config)
  end

  @spec needs_dp_coordinator(SnakeBridge.Ref.t()) :: {:ok, term()} | {:error, Snakepit.Error.t()}
  def needs_dp_coordinator(ref) do
    SnakeBridge.Runtime.get_attr(ref, :needs_dp_coordinator)
  end

  @spec observability_config(SnakeBridge.Ref.t()) :: {:ok, term()} | {:error, Snakepit.Error.t()}
  def observability_config(ref) do
    SnakeBridge.Runtime.get_attr(ref, :observability_config)
  end

  @spec optimization_level(SnakeBridge.Ref.t()) :: {:ok, term()} | {:error, Snakepit.Error.t()}
  def optimization_level(ref) do
    SnakeBridge.Runtime.get_attr(ref, :optimization_level)
  end

  @spec parallel_config(SnakeBridge.Ref.t()) :: {:ok, term()} | {:error, Snakepit.Error.t()}
  def parallel_config(ref) do
    SnakeBridge.Runtime.get_attr(ref, :parallel_config)
  end

  @spec profiler_config(SnakeBridge.Ref.t()) :: {:ok, term()} | {:error, Snakepit.Error.t()}
  def profiler_config(ref) do
    SnakeBridge.Runtime.get_attr(ref, :profiler_config)
  end

  @spec quant_config(SnakeBridge.Ref.t()) :: {:ok, term()} | {:error, Snakepit.Error.t()}
  def quant_config(ref) do
    SnakeBridge.Runtime.get_attr(ref, :quant_config)
  end

  @spec scheduler_config(SnakeBridge.Ref.t()) :: {:ok, term()} | {:error, Snakepit.Error.t()}
  def scheduler_config(ref) do
    SnakeBridge.Runtime.get_attr(ref, :scheduler_config)
  end

  @spec speculative_config(SnakeBridge.Ref.t()) :: {:ok, term()} | {:error, Snakepit.Error.t()}
  def speculative_config(ref) do
    SnakeBridge.Runtime.get_attr(ref, :speculative_config)
  end

  @spec structured_outputs_config(SnakeBridge.Ref.t()) ::
          {:ok, term()} | {:error, Snakepit.Error.t()}
  def structured_outputs_config(ref) do
    SnakeBridge.Runtime.get_attr(ref, :structured_outputs_config)
  end
end
